---
layout: post
type: "MECSEAIML"
subject: "IA"
section: "Unit 1: Introduction and Image Enhancement"
title:  "1. Introduction to Image Analysis"
author: Jitender Singh Virk
---

## Terminology
The different names of the same subject can cause confusion. Following are the names and areas that are similar and interchangeable:
* {3D, Computer, Machine, Robot} Vision
* Image {Processing, Analysis, Understanding, Interpretation}
* Medical Image {Analysis, Processing}
* Signal Processing

There is no general agreement among authors regarding where image processing stops and other related areas, such as image analysis and computer vision, start. Sometimes, a distinction is made by defining image processing as a discipline in which both the input and output of a process are images. We believe this to be a limiting and somewhat artificial boundary. For example, under this definition, even the trivial task of computing the average intensity of an image (which yields a single number) would not be considered an image processing operation. On the other hand, there are fields such as computer vision whose ultimate goal is to use computers to emulate human vision, including learning and being able to make inferences and take actions based on visual inputs. This area itself is a branch of artificial intelligence (AI) whose objective is to emulate human intelligence. The field of AI is in its earliest stages of infancy in terms of development, with progress having been much slower than originally anticipated. The area of image analysis (also called image understanding) is in between image processing and computer vision.

## What is Digital Image Processing?
An image may be defined as a two-dimensional function, f(x, y), where x and y are spatial (plane) coordinates, and the amplitude of f at any pair of coordinates (x, y) is called the intensity or gray level of the image at that point. When x, y, and the intensity values of f are all finite, discrete quantities, we call the image a digital image. The field of digital image processing refers to processing digital images by means of a digital computer. Note that a digital image is composed of a finite number of elements, each of which has a particular location and value. These elements are called picture elements (pels), image elements, and pixels. Pixel is the term used most widely to denote the elements of a digital image.

To sum up in one line - The intelligent, concise summary of the content of images is image analysis.

The content of the image can be one or more of the following (1 is the lower level of information and 6 is the higher level of information):
1. How blurry is it?
2. are there edges in it?
3. What objects are in it?
4. What are those people in the image doing?
5. What are those people doing?
6. Is this image elegant, grim, funny, or cute?

There are no clear-cut boundaries in the continuum from image processing at one end to computer vision at the other. However, one useful paradigm is to consider three types of computerized processes in this continuum: low-, mid-, and high-level processes. Low-level processes involve primitive operations such as image preprocessing to reduce noise, contrast enhancement, and image sharpening. A low-level process is characterized by the fact that both its inputs and outputs are images. Mid-level processing of images involves tasks such as segmentation (partitioning an image into regions or objects), description of those objects to reduce them to a form suitable for computer processing, and classification (recognition) of individual objects. A mid-level process is characterized by the fact that its inputs generally are images, but its outputs are attributes extracted from those images (e.g., edges, contours, and the identity of individual
objects). Finally, higher-level processing involves “making sense” of an ensemble of recognized objects, as in image analysis, and, at the far end of the continuum, performing the cognitive functions normally associated with human vision.

## Analog vs digital images
**Analog images** are the type of images that we, as humans, look at. These images are specifically used for human viewing. They include photographs, paintings, TV images, and all of our medical images recorded on film or displayed on various display devices, like computer monitors. In an analog image, generally, we see various levels of brightness (or film density) and colors. It is generally continuous and not broken into many small individual pieces.

**Digital images** are recorded as many numbers. The image is divided into a matrix or array of small picture elements, or pixels. Each pixel is represented by a numerical value. The advantage of digital images is that they can be processed, in many ways, by computer systems. In general, the pixel value is related to the brightness or color that we will see when the digital image is converted into an analog image for display and viewing. A clear distinction between an analog and a digital image is depicted in below image.

<img src="/assets/20MAI/IA/analogvsdigital.jpg" class="rounded mx-auto d-block" alt="Scientific Method image" style="max-height: 30rem; max-width: 97%;">

## Relationship between a digital image and a signal
If the image is a two dimensional array then what does it have to do with a signal? In order to understand that , We need to first understand what is a signal?

**Signal**: In physical world, any quantity measurable through time over space or any higher dimension can be taken as a signal. A signal is a mathematical function, and it conveys some information. A signal can be one dimensional or two dimensional or higher dimensional signal. One dimensional signal is a signal that is measured over time. The common example is a voice signal. The two dimensional signals are those that are measured over some other physical quantities. The example of two dimensional signal is a digital image.

**Relationship**: Since anything that conveys information or broadcast a message in physical world between two observers is a signal. That includes speech or (human voice) or an image as a signal. Since when we speak , our voice is converted to a sound wave/signal and transformed with respect to the time to person we are speaking to. Not only this , but the way a digital camera works, as while acquiring an image from a digital camera involves transfer of a signal from one part of the system to the other.

## The Origins of Digital Image Processing
The first computers powerful enough to carry out meaningful image processing tasks appeared in the early 1960s. The birth of what we
call digital image processing today can be traced to the availability of those machines, and to the onset of the space program during
that period. It took the combination of those two developments to bring into focus the potential of digital image processing for solving
problems of practical significance. Work on using computer techniques for improving images from a space probe began at the Jet
Propulsion Laboratory (Pasadena, California) in 1964, when pictures of the moon transmitted by Ranger 7 were processed by a
computer to correct various types of image distortion inherent in the on-board television camera.

In parallel with space applications, digital image processing techniques began in the late 1960s and early 1970s to be used in medical
imaging, remote Earth resources observations, and astronomy. The invention in the early 1970s of computerized axial tomography
(CAT), also called computerized tomography (CT) for short, is one of the most important events in the application of image processing
in medical diagnosis.

From the 1960s until the present, the field of image processing has grown vigorously. In addition to applications in medicine and the
space program, digital image processing techniques are now used in a broad range of applications. Computer procedures are used to
enhance the contrast or code the intensity levels into color for easier interpretation of X-rays and other images used in industry,
medicine, and the biological sciences. Geographers use the same or similar techniques to study pollution patterns from aerial and
satellite imagery. Image enhancement and restoration procedures are used to process degraded images of unrecoverable objects, or
experimental results too expensive to duplicate. In archeology, image processing methods have successfully restored blurred pictures
that were the only available records of rare artifacts lost or damaged after being photographed. In physics and related fields, computer
techniques routinely enhance images of experiments in areas such as high-energy plasmas and electron microscopy. Similarly
successful applications of image processing concepts can be found in astronomy, biology, nuclear medicine, law enforcement, defense,
and industry.

## Motivation and Perspective
Image analysis is a field of computer science that deals with extraction of meaningful information from digital images by applying different digital image processing techniques. It involves the fields of computer or machine vision and medical imaging and also makes extensive use of pattern recognition, digital geometry and signal processing. This field of computer science was introduced in 1950s at academic institutions as a branch of Artificial Intelligence and Robotics. Image Analysis is considered to be a quantitative and qualitative characterization of 2-Dimensional and 3-Dimensional Images. There are many different techniques used in automatically analyzing images.

Examples of image analysis techniques in different fields include:
* 2D and 3D object recognition
* Image Segmentation
* Motion Detection
* Video Tracking
* Medical Scan Analysis
* 3D pose estimation
* Automatic Number plate recognition etc.

As image analysis is highly dependent on different digital image processing techniques so it is considered to be synonymous to digital image processing.

## Applications of Digital Image Processing
Since digital image analysis/processing has very wide range of applications and has impacted all technical fields. Some of the major applications are

#### Image sharpening and restoration
Image sharpening and restoration refers here to process images that have been captured from the modern camera to make them a better image or to manipulate those images in way to achieve desired result. It refers to do what Adobe Photoshop usually does. This includes Zooming, blurring , sharpening , gray scale to color conversion, detecting edges and vice versa , Image retrieval and Image recognition.

#### Gamma-Ray Imaging
Major uses of imaging based on gamma rays include nuclear medicine and astronomical observations. In nuclear medicine, the approach is to inject a patient with a radioactive isotope that emits gamma rays as it decays. Images are produced from the emissions collected by gamma-ray detectors. Images of this sort are used to locate sites of bone pathology, such as infections or tumors

#### Medical CT
The invention in the early 1970s of computerized axial tomography (CAT), also called computerized tomography (CT) for short, is one of the most important events in the application of image processing in medical diagnosis. Computerized axial tomography is a process in which a ring of detectors encircles an object (or patient) and an X-ray source, concentric with the detector ring, rotates about the object. The X-rays pass through the object and are collected at the opposite end by the corresponding detectors in the ring. This procedure is repeated the source rotates.

#### PET Scan
Another modality of nuclear imaging is positron emission tomography (PET). The principle is the same as with X-ray tomography. However, instead of using an external source of X-ray energy, the patient is given a radioactive isotope that emits positrons as it decays. When a positron meets an electron, both are annihilated and two gamma rays are given off. These are detected and a tomographic image is created using the basic principles of tomography.

#### X-Ray Imaging
X-rays are among the oldest sources of EM radiation used for imaging. The best known use of X-rays is medical diagnostics, but they are also used extensively in industry and other areas, such as astronomy. The intensity of the X-rays is modified by absorption as they pass through the patient, and the resulting energy falling on the film develops it, much in the same way that light develops photographic film. In digital radiography, digital images are obtained by one of two methods: (1) by digitizing X-ray films; or; (2) by having the X rays that pass through the patient fall directly onto devices (such as a phosphor screen) that convert X-rays to light. The light signal in turn is captured by a light- sensitive digitizing system.

#### Imaging in the Ultraviolet Band
Applications of ultraviolet “light” are varied. They include lithography, industrial inspection, microscopy, lasers, biological imaging, and astronomical observations. We illustrate imaging in this band with examples from microscopy and astronomy.

Ultraviolet light is used in fluorescence microscopy, one of the fastest growing areas of microscopy. Fluorescence is a phenomenon discovered in the middle of the nineteenth century, when it was first observed that the mineral fluorspar fluoresces when ultraviolet light is directed upon it. The ultraviolet light itself is not visible, but when a photon of ultraviolet radiation collides with an electron in an atom of a fluorescent material, it elevates the electron to a higher energy level. Subsequently, the excited electron relaxes to a lower level and emits light in the form of a lower-energy photon in the visible (red) light region. Important tasks performed with a fluorescence microscope are to use an excitation light to irradiate a prepared specimen, and then to separate the much weaker radiating fluorescent light from the brighter excitation light. Thus, only the emission light reaches the eye or other detector. The resulting fluorescing areas shine against a dark background with sufficient contrast to permit detection. The darker the background of the nonfluorescing material, the more efficient the instrument.

#### Imaging in the Visible and Infrared Bands
Considering that the visual band of the electromagnetic spectrum is the most familiar in all our activities, it is not surprising that imaging in this band outweighs by far all the others in terms of breadth of application. The infrared band often is used in conjunction with visual imaging, so we have grouped the visible and infrared bands in this section for the purpose of illustration. We consider in the following discussion applications in light microscopy, astronomy, remote sensing, industry, and law enforcement.

Another major area of visual processing is remote sensing, which usually includes several bands in the visual and infrared regions of
the spectrum.

#### Imaging in the Microwave Band
The principal application of imaging in the microwave band is radar. The unique feature of imaging radar is its ability to collect data over virtually any region at any time, regardless of weather or ambient lighting conditions. Some radar waves can penetrate clouds, and under certain conditions, can also see through vegetation, ice, and dry sand. In many cases, radar is the only way to explore inaccessible regions of the Earth’s surface. An imaging radar works like a flash camera in that it provides its own illumination (microwave pulses) to illuminate an area on the ground and take a snapshot image. Instead of a camera lens, a radar uses an antenna and digital computer processing to record its images. In a radar image, one can see only the microwave energy that was reflected back toward the radar antenna.

#### Imaging in the Radio Band
As in the case of imaging at the other end of the spectrum (gamma rays), the major applications of imaging in the radio band are in
medicine and astronomy. In medicine, radio waves are used in magnetic resonance imaging (MRI). This technique places a patient in a
powerful magnet and passes radio waves through the individual’s body in short pulses. Each pulse causes a responding pulse of radio
waves to be emitted by the patient’s tissues. The location from which these signals originate and their strength are determined by a
computer, which produces a two-dimensional image of a section of the patient. MRI can produce images in any plane. Figure 1.17
shows MRI images of a human knee and spine.

#### UV Imaging
In the field of remote sensing, the area of the earth is scanned by a satellite or from a very high ground and then it is analyzed to obtain information about it. One particular application of digital image processing in the field of remote sensing is to detect infrastructure damages caused by an earthquake.

As it takes longer time to grasp damage, even if serious damages are focused on. Since the area effected by the earthquake is sometimes so wide , that it not possible to examine it with human eye in order to estimate damages. Even if it is, then it is very hectic and time consuming procedure. So a solution to this is found in digital image processing. An image of the effected area is captured from the above ground and then it is analyzed to detect the various types of damage done by the earthquake.
The key steps include in the analysis are
* The extraction of edges
* Analysis and enhancement of various types of edges

#### Transmission and encoding
The very first image that has been transmitted over the wire was from London to New York via a submarine cable. The picture that was sent took three hours to reach from one place to another. Now just imagine, that today we are able to see live video feed, or live CCTV footage from one continent to another with just a delay of seconds. It means that a lot of work has been done in this field too. This field does not only focus on transmission, but also on encoding. Many different formats have been developed for high or low bandwidth to encode photos and then stream it over the internet or e.t.c.

#### Machine/Robot vision
Apart form the many challenges that a robot face today, one of the biggest challenge still is to increase the vision of the robot. Make robot able to see things, identify them, identify the hurdles e.t.c. Much work has been contributed by this field and a complete other field of computer vision has been introduced to work on it.

#### Hurdle detection
Hurdle detection is one of the common task that has been done through image processing, by identifying different type of objects in the image and then calculating the distance between robot and hurdles.

#### Line follower robot
Most of the robots today work by following the line and thus are called line follower robots. This help a robot to move on its path and perform some tasks. This has also been achieved through image processing.

#### Color processing
Color processing includes processing of colored images and different color spaces that are used. For example RGB color model, YCbCr, HSV. It also involves studying transmission, storage, and encoding of these color images.

#### Pattern recognition
Pattern recognition involves study from image processing and from various other fields that includes machine learning (a branch of artificial intelligence). In pattern recognition, image processing is used for identifying the objects in an images and then machine learning is used to train the system for the change in pattern. Pattern recognition is used in computer aided diagnosis, recognition of handwriting, recognition of images e.t.c.

#### Video processing
A video is nothing but just the very fast movement of pictures. The quality of the video depends on the number of frames/pictures per minute and the quality of each frame being used. Video processing involves noise reduction, detail enhancement, motion detection, frame rate conversion, aspect ratio conversion, color space conversion e.t.c.


## Fundamental Steps in Digital Image Processing
<img src="/assets/20MAI/IA/ia_fundamentals.png" class="rounded mx-auto d-block" alt="Image Analysis fundamentals" style="max-width: 97%;">

1. **Image acquisition** is the first process in Digital Image Processing/Analysis as shown in the figure above. In this step, the image is retrieved from some source, usually a hardware based source. Note that acquisition could be as simple as being given an image that is already in digital form. The image acquisition stage involves pre-processing, such as scaling.

2. **Image enhancement** is the process of manipulating an image so the result is more suitable than the original for a specific application. The word specific is important here, because it establishes at the outset that enhancement techniques are problem oriented. Thus, for example, a method that is quite useful for enhancing X-ray images may not be the best approach for enhancing satellite images taken in the infrared band of the electromagnetic spectrum. Basically, the idea behind enhancement techniques is to bring out detail that is obscured, or simply to highlight certain features of interest in an image. A familiar example of enhancement is when we increase the contrast of an image because it is more pleasing to eyes. Usually this process includes sharpening of images, brightness and contrast adjustment, removal of noise etc.

3. **Image restoration** is an area that also deals with improving the appearance of an image. However, unlike enhancement, which is subjective, image restoration is objective, in the sense that restoration techniques tend to be based on mathematical or probabilistic models of image degradation. Enhancement, on the other hand, is based on human subjective preferences regarding what constitutes a “good” enhancement result.

4. **Color image processing**, as the name specifies, involves image processing of colored images either as indexed images or RGB images. This area has been gaining importance because of the significant increase in the use of digital images over the Internet. Moreover, color is used as a basis for extracting features of interest in an image.

5. Wavelets and Multiresolution Processing: Wavelets are the foundation for representing images in various degrees of resolution. Wavelets are generally small waves of limited duration which are used to calculate wavelet transform that gives time-frequency information. Images subdivision successively into smaller regions for data compression and for pyramidal representation. Multiresolution is the process of representing images in various degrees of resolution.

6. **Compression**, as the name implies, deals with techniques for reducing the storage required to save an image, or the bandwidth required to transmit it. Although storage technology has improved significantly over the past decade, the same cannot be said for transmission capacity. This is true particularly in uses of the internet, which are characterized by significant pictorial content. Image compression is familiar (perhaps inadvertently) to most users of computers in the form of image file extensions, such as the jpg file extension used in the JPEG (Joint Photographic Experts Group) image compression standard.

7. **Morphological processing** deals with tools for extracting image components that are useful in the representation and description of shape. It includes basic morphological operations like erosion and dilation.

8. **Segmentation** partitions an image into its constituent parts or objects. In general, autonomous segmentation is one of the most difficult tasks in digital image processing. A rugged segmentation procedure brings the process a long way toward successful solution of imaging problems that require objects to be identified individually. On the other hand, weak or erratic segmentation algorithms almost always guarantee eventual failure. In general, the more accurate the segmentation, the more likely automated object classification is to succeed.

9. **Feature extraction or Representation and description** almost always follow the output of a segmentation stage, which usually is raw pixel data, constituting either the boundary of a region (i.e., the set of pixels separating one image region from another) or all the points in the region itself. In either case, converting the data to a form suitable for computer processing is necessary. The first decision that must be made is whether the data should be represented as a boundary or as a complete region. Boundary representation is appropriate when the focus is on external shape characteristics, such as corners and inflections. Regional representation is appropriate when the focus is on internal properties, such as texture or skeletal shape. In some applications, these representations complement each other. Choosing a representation is only part of the solution for transforming raw data into a form suitable for subsequent computer processing. A method must also be specified for describing the data so that features of interest are highlighted. Description, also called feature selection, deals with extracting attributes that result in some quantitative information of interest or are basic for differentiating one class of objects from another.

10. **Object recognition or Image pattern classification** is the process that assigns a label (e.g., “vehicle”) to an object based on its descriptors. We conclude our coverage of digital image processing with the development of methods for recognition of individual objects.


11. **Knowledge Base**: Knowledge about a problem domain is coded into an image processing system in the form of a knowledge base. This knowledge may be as simple as detailing regions of an image where the information of interest is known to be located, thus limiting the search that has to be conducted in seeking that information. The knowledge base can also be quite complex, such as an interrelated list of all major possible defects in a materials inspection problem, or an image database containing high-resolution satellite images of a region in connection with change-detection applications. In addition to guiding the operation of each processing module, the knowledge base also controls the interaction between different modules shown in figure above.

## Components of Imaging Processing System
As recently as the mid-1980s, numerous models of image processing systems being sold throughout the world were rather substantial peripheral devices that attached to equally substantial host computers. Late in the 1980s and early in the 1990s, the market shifted to image processing hardware in the form of single boards designed to be compatible with industry standard buses and to fit into engineering workstation cabinets and personal computers. In the late 1990s and early 2000s, a new class of add-on boards, called graphics processing units (GPUs) were introduced for work on 3-D applications, such as games and other 3-D graphics applications. It was not long before GPUs found their way into image processing applications involving large-scale matrix implementations, such as training deep convolutional networks. In addition to lowering costs, the market shift from substantial peripheral devices to add-on processing boards also served as a catalyst for a significant number of new companies specializing in the development of software written specifically for image processing.

<img src="/assets/20MAI/IA/iacomponents.png" class="rounded mx-auto d-block" alt="Image Analysis components" style="max-width: 97%; max-height:45rem;">

The trend continues toward miniaturizing and blending of general-purpose small computers with specialized image processing hardware and software. Above figure shows the basic components comprising a typical general-purpose system used for digital image processing.

* **Image Sensing**: With reference to sensing, two elements are required to acquire digital images. The first is a physical device that is sensitive to the energy radiated by the object we wish to image. The second, called a *digitizer*, is a device for converting the output of the physical sensing device into digital form. For instance, in a digital video camera, the sensors produce an electrical output proportional to light intensity. The digitizer converts these outputs to digital data. Specialized image processing hardware usually consists of the digitizer just mentioned, plus hardware that performs other primitive operations, such as an arithmetic logic unit (ALU), which performs arithmetic and logical operations in parallel on entire images. One example of how an ALU is used is in averaging images as quickly as they are digitized, for the purpose of noise reduction. This type of hardware sometimes is called a front-end subsystem, and its most distinguishing characteristic is speed. In other words, this unit performs functions that require fast data throughputs (e.g., digitizing and averaging video images at 30 frames per second (FPS)) that the typical main computer cannot handle.

* **Computer**: The computer in an image processing system is a general-purpose computer and can range from a PC to a supercomputer. In dedicated applications, sometimes custom computers are used to achieve a required level of performance, but our interest here is on general-purpose image processing systems. In these systems, almost any well-equipped PC-type machine is suitable for off-line image processing tasks.

* **Software** for image processing consists of specialized modules that perform specific tasks. A well-designed package also includes the capability for the user to write code that, as a minimum, utilizes the specialized modules. More sophisticated software packages allow the integration of those modules and general-purpose software commands from at least one computer language. Commercially available image processing software, such as the well-known MATLAB® Image Processing Toolbox, is also common in a well-equipped image processing system.

* **Mass storage** is a must in image processing applications. An image of size 1024 × 1024 pixels, in which the intensity of each pixel is an 8-bit quantity, requires one megabyte of storage space if the image is not compressed. When dealing with image databases that contain thousands, or even millions, of images, providing adequate storage in an image processing system can be a challenge. Digital storage for image processing applications falls into three principal categories: (1) short-term storage for use during processing; (2) on-line storage for relatively fast recall; and (3) archival storage, characterized by inrequent access. Storage is measured in bytes (eight bits), Kbytes ( 10<sup>3</sup> bytes), Mbytes ( 10<sup>6</sup> bytes), Gbytes ( 10<sup>9</sup> bytes), and Tbytes ( 10<sup>12</sup> bytes). One method of providing short-term storage is computer memory. Another is by specialized boards, called frame buffers, that store one or more images and can be accessed rapidly, usually at video rates (e.g., at 30 complete images per second). The latter method allows virtually instantaneous image zoom, as well as scroll (vertical shifts) and pan (horizontal shifts). Frame buffers usually are housed in the specialized image processing hardware unit in figure shown above. On-line storage generally takes the form of magnetic disks or optical-media storage. The key factor characterizing on-line storage is frequent access to the stored data. Finally, archival storage is characterized by massive storage requirements but infrequent need for access. Magnetic tapes and optical disks housed in “jukeboxes” are the usual media for archival applications.

* **Image displays** in use today are mainly color, flat screen monitors. Monitors are driven by the outputs of image and graphics display cards that are an integral part of the computer system. Seldom are there requirements for image display applications that cannot be met by display cards and GPUs available commercially as part of the computer system. In some cases, it is necessary to have stereo displays, and these are implemented in the form of headgear containing two small displays embedded in goggles worn by the user.

* **Hardcopy** devices for recording images include laser printers, film cameras, heat-sensitive devices, ink-jet units, and digital units, such as optical and CD ROM disks. Film provides the highest possible resolution, but paper is the obvious medium of choice for written material. For presentations, images are displayed on film transparencies or in a digital medium if image projection equipment is used. The latter approach is gaining acceptance as the standard for image presentations.

* **Networking and cloud** communication are almost default functions in any computer system in use today. Because of the large amount of data inherent in image processing applications, the key consideration in image transmission is bandwidth. In dedicated networks, this typically is not a problem, but communications with remote sites via the internet are not always as efficient. Fortunately, transmission bandwidth is improving quickly as a result of optical fiber and other broadband technologies. Image data compression continues to play a major role in the transmission of large amounts of image data.

---
## FAQs
* What are different application areas of Image analysis?
* Define Digital Image Processing?
* What are different sources of energy used in image processing?
* Outline the application areas where Gamma Ray and X-Ray imaging is needed.
* Explain different fundamental steps required in digital image processing.
* What are different components of Image Processing System?
* The insufficient number of intensity levels used to represent a smooth area in a digital image causes **False Contouring**
* What is the significance of using Image interpolation?
* The number of bits required to store 7 bit digital image of size 23 x 27 ?
* A pixel p at coordinate (x, y) has four horizontal and vertical neighbors whose coordinates are given by (x+1, y), (x, y+1), (x-­1, y), (x, y-1).


---
##### References
* Book: Digital Image Processing, Rafael C. Gonzalez and Richard E. Woods, 4th edition

* [Applications](https://www.tutorialspoint.com/dip/applications_and_usage.htm)
