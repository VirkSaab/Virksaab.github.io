{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment Analysis**: Given a sentence, analysing whether the sentence is sad, happy, angry, etc. For example, _Woho! I got selected in Harvard university!_ reflects happy sentiment. _I lost my phone in subway_ reflects sad sentiment. Usually, we use tweets data for sentiment analysis but, ofcourse, you can use any type of data.\n",
    "\n",
    "To do sentiment analysis, we also need a _vocabulary_.\n",
    "\n",
    "**Vocabulary**: It is a set of unique words that appear in the data. Usually, we build this vocab before training a model but we can use predefined vocabulary as well. For this project, we'll build it from scratch. As we cannot input strings or  words to a model because machine learning models need numerical data. Vocabulary is required to create features from words and sentences to train a model. For example, _I lost my phone in subway. I am stupid._ will create a vocabulary that contains I, lost, my, phone, in, subway, am, stupid. Now, there are several ways to create features from these words.\n",
    "\n",
    "Watch [this video](https://www.coursera.org/learn/classification-vector-spaces-in-nlp/lecture/gNXI3/vocabulary-feature-extraction) for more details on vocabulary and feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**: To move further, we first need a dataset to work on. Let's use [movie reviews data](http://ai.stanford.edu/~amaas/data/sentiment/). This data is a binary sentiment data. Positive reviews and negative reviews. Download the data first then follow along. This is a very large dataset and it might be overwhelming for beginners but using this dataset will also uncover common issues dealing with large datasets in machine learning such as efficient handling, preprocessing and underfitting problems.\n",
    "\n",
    "A vocabulary file is already provided with the dataset as `imdb.vocab` file. But, let's create ours own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below command to unzip the aclImdb_v1.tar.gz downloaded dataset.\n",
    "# !tar -xvf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pt)",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
